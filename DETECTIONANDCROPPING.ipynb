{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ac6bdb-f03a-46cc-8487-a08f374f03f8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "DETECTION MODEL AND CROPPING ALGORTIHM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cfbf0c-02c8-4ae7-a7ba-de6d49cdc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db222cd-1bab-48cc-81e0-0681bf5c36f0",
   "metadata": {},
   "source": [
    "50 BORING EPOCH TRAINING CYCLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32099d1-4781-41ef-8661-a040938aeac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6.25M/6.25M [00:02<00:00, 2.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.104  Python-3.11.8 torch-2.6.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\wild\\data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Vidya\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 755k/755k [00:00<00:00, 4.94MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\wild\\train\\labels... 583 images, 0 backgrounds, 0 corrupt: 100%|██████████| 583/583 [00:02<00:00, 21\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\wild\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\wild\\valid\\labels... 167 images, 0 backgrounds, 0 corrupt: 100%|██████████| 167/167 [00:00<00:00, 191.\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\wild\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.082      2.369       1.22         24        640: 100%|██████████| 37/37 [06:41<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:38<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.641     0.0187      0.421      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.137      1.762      1.243         14        640: 100%|██████████| 37/37 [05:55<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.258      0.474      0.208      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.242      1.663      1.319         25        640: 100%|██████████| 37/37 [05:43<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:34<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.676      0.526      0.596      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.185      1.535        1.3         10        640: 100%|██████████| 37/37 [05:37<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:34<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.348      0.381      0.326      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.201      1.419       1.32         13        640: 100%|██████████| 37/37 [06:56<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:43<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.871      0.716      0.786      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.154      1.292      1.293         13        640: 100%|██████████| 37/37 [06:10<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:35<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.726      0.742      0.766      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.144      1.174      1.256         15        640: 100%|██████████| 37/37 [05:54<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194       0.84      0.704      0.815      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.062      1.153      1.266          7        640: 100%|██████████| 37/37 [06:00<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:33<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.831      0.706      0.812      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.052        1.1      1.219         16        640: 100%|██████████| 37/37 [07:47<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:47<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.892      0.723      0.871      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G       1.03      1.064      1.233         12        640: 100%|██████████| 37/37 [11:23<00:00, 18.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:52<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.871      0.766       0.87      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.006      1.045      1.225         15        640: 100%|██████████| 37/37 [12:04<00:00, 19.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:38<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.902      0.747      0.872       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G     0.9694     0.9868      1.178         19        640: 100%|██████████| 37/37 [06:05<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:37<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.907      0.805      0.903      0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.9606      0.955      1.171         17        640: 100%|██████████| 37/37 [06:23<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:39<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.834      0.835      0.886      0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.9776     0.9278      1.175         13        640: 100%|██████████| 37/37 [06:02<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:35<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.927      0.758      0.909      0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.9169     0.8973      1.147         13        640: 100%|██████████| 37/37 [06:54<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:38<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.883      0.814      0.919      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.9018     0.9012      1.154         11        640: 100%|██████████| 37/37 [06:06<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.903      0.812      0.896      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G     0.8672     0.8389      1.108         19        640: 100%|██████████| 37/37 [05:59<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:34<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.929      0.825      0.906      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.8741     0.8733      1.129          7        640: 100%|██████████| 37/37 [05:45<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:34<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.923       0.82      0.915      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.8682     0.8466      1.142         20        640: 100%|██████████| 37/37 [05:47<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:33<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.853       0.84      0.924      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.8635     0.8455      1.126         22        640: 100%|██████████| 37/37 [05:47<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:31<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.909      0.821       0.92      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G      0.802     0.8015      1.108         14        640: 100%|██████████| 37/37 [05:16<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:32<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.929       0.88      0.946      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.8016      0.802      1.092          9        640: 100%|██████████| 37/37 [06:28<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:37<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.877      0.897      0.948      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G     0.8313     0.8171      1.114         13        640: 100%|██████████| 37/37 [06:55<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:35<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.889      0.876      0.935       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G     0.7759     0.7544      1.097         22        640: 100%|██████████| 37/37 [06:50<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:42<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.913      0.861      0.932      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G     0.7828     0.7619       1.09         15        640: 100%|██████████| 37/37 [07:28<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:43<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.914      0.851      0.927      0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G     0.7667     0.7582      1.108         18        640: 100%|██████████| 37/37 [06:59<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.908      0.865      0.944      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G     0.7608      0.722      1.088         16        640: 100%|██████████| 37/37 [06:37<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:42<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.906      0.845      0.947      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G     0.7608     0.7357      1.079         16        640: 100%|██████████| 37/37 [06:25<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:38<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.881      0.902      0.944      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G     0.7465     0.6912      1.065         14        640: 100%|██████████| 37/37 [06:10<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:37<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.914      0.877      0.954      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G     0.7167     0.6667      1.058         15        640: 100%|██████████| 37/37 [06:07<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.882      0.883      0.941      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G     0.6983     0.6645      1.056         19        640: 100%|██████████| 37/37 [06:32<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:44<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.943      0.847      0.942      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G     0.6924     0.6653      1.055         13        640: 100%|██████████| 37/37 [07:13<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:41<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.946      0.851      0.943      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G     0.6923     0.6534      1.047         14        640: 100%|██████████| 37/37 [06:51<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:42<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.885      0.897      0.944      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G     0.6612      0.633      1.027         20        640: 100%|██████████| 37/37 [06:51<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:41<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.961      0.866      0.957      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G     0.6525     0.6319      1.021         18        640: 100%|██████████| 37/37 [4:07:55<00:00, 4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:39<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.926      0.905      0.959      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G     0.6384     0.6159      1.017         16        640: 100%|██████████| 37/37 [06:17<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:37<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.923      0.907      0.956      0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G     0.6409     0.6108       1.03         12        640: 100%|██████████| 37/37 [06:12<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:37<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.921      0.902      0.959      0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G     0.6398     0.6198       1.01          6        640: 100%|██████████| 37/37 [06:25<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:38<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.917      0.923      0.948      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G     0.6422     0.6093      1.023         16        640: 100%|██████████| 37/37 [06:27<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:42<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.927      0.921      0.967      0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.6134     0.5897      1.021         18        640: 100%|██████████| 37/37 [06:53<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:44<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.892      0.928      0.959      0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G     0.5522     0.5048     0.9779          8        640: 100%|██████████| 37/37 [06:47<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:43<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.907      0.905      0.928      0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G     0.5605     0.4839     0.9846         10        640: 100%|██████████| 37/37 [07:02<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:42<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.932      0.921      0.958      0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G     0.5145     0.4454     0.9835          8        640: 100%|██████████| 37/37 [1:02:06<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:34<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.909      0.897      0.944      0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G     0.5047     0.4393     0.9493          8        640: 100%|██████████| 37/37 [05:53<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:34<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.939      0.867      0.952      0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G     0.4925     0.4243     0.9449         10        640: 100%|██████████| 37/37 [06:30<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:46<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.908      0.907      0.946      0.838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G     0.4937     0.4174     0.9467         10        640: 100%|██████████| 37/37 [06:26<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.905      0.912      0.949      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G     0.4729     0.4255     0.9438          9        640: 100%|██████████| 37/37 [06:14<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:35<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.931      0.911      0.953      0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G     0.4749     0.4118     0.9327          7        640: 100%|██████████| 37/37 [05:57<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:36<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.922      0.915      0.952      0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G     0.4483     0.3949     0.9332          7        640: 100%|██████████| 37/37 [06:05<00:00,  9.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:42<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.926      0.907      0.949      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G     0.4494      0.382     0.9327          9        640: 100%|██████████| 37/37 [06:24<00:00, 10.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:49<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.924      0.923      0.954       0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 11.014 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.104  Python-3.11.8 torch-2.6.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:33<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.924      0.923      0.954       0.86\n",
      "Speed: 4.6ms preprocess, 171.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model (for object detection)\n",
    "model = YOLO(\"yolov8n.pt\")  # or yolov8s.pt for more accuracy\n",
    "\n",
    "# Train on your dataset\n",
    "results = model.train(data=\"C:\\wild\\data.yaml\", epochs=50, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515c44b-7e23-43ee-921e-a743918318b9",
   "metadata": {},
   "source": [
    "MODEL IS READY AFTER EPOCH TRAINING\n",
    "BELOW IS ACCURACY MEASURE AND SAMPLE TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "773d29f1-97fc-413f-8327-78a5f4bccf68",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.104  Python-3.11.8 torch-2.6.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\wild\\valid\\labels.cache... 167 images, 0 backgrounds, 0 corrupt: 100%|██████████| 167/167 [00:00<?, ?i\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        194      0.924      0.923      0.954       0.86\n",
      "Speed: 2.3ms preprocess, 106.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56f23960-08b8-4840-a663-b52df7fc2a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\RoadSafeAi\\data\\wild\\test\\images\\samplemanthan.jpg: 640x448 1 license_plate, 355.1ms\n",
      "Speed: 6.3ms preprocess, 355.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns\\detect\\predict6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE IMAGE TESTING\n",
    "results = model.predict(r\"C:\\RoadSafeAi\\data\\wild\\test\\images\\samplemanthan.jpg\", save=True, conf=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee257900-040a-4310-8124-f002babe11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\wild\\test\\images\\sample2.jpg: 640x480 1 license_plate, 505.4ms\n",
      "Speed: 37.3ms preprocess, 505.4ms inference, 31.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns\\detect\\train15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE IMAGE TESTING\n",
    "results = model.predict(r\"C:\\wild\\test\\images\\sample2.jpg\", save=True, conf=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54201a72-6895-4d15-ac94-2e8a76d9af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\wild\\test\\images\\sample3.jpg: 640x480 1 license_plate, 121.5ms\n",
      "Speed: 72.6ms preprocess, 121.5ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE IMAGE TESTING\n",
    "results = model.predict(r\"C:\\wild\\test\\images\\sample3.jpg\", save=True, conf=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f001262-3705-49f1-a0b1-68e02ad5276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\wild\\test\\images\\sample4.jpg: 416x640 1 license_plate, 194.9ms\n",
      "Speed: 8.3ms preprocess, 194.9ms inference, 2.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE IMAGE TESTING\n",
    "results = model.predict(r\"C:\\wild\\test\\images\\sample4.jpg\", save=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eeaa3c2-e282-4b9d-8494-8609bca6bb7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Find the most recent folder in runs/detect/\n",
    "detect_folders = sorted(glob('runs/detect/train13'), key=os.path.getmtime, reverse=True)\n",
    "latest_folder = detect_folders[0]\n",
    "\n",
    "# Find the latest image in that folder\n",
    "result_images = sorted(glob(os.path.join(latest_folder, 'sample.jpg')), key=os.path.getmtime, reverse=True)\n",
    "latest_result_image = result_images[0]\n",
    "\n",
    "# Read and display the image\n",
    "img = cv2.imread(latest_result_image)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.title('YOLOv8 License Plate Detection Output')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54700d28-cd80-4224-a200-18c784378215",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace with actual path of the saved image\n",
    "img_path = \"runs/detect/train13/sample.jpg\"\n",
    "\n",
    "# Load and show the image\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.title('Detected License Plate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b521ea-1f56-4d89-a543-8c3058835e25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the path to the YOLO-detected image\n",
    "img_path = \"runs/detect/train13/sample.jpg\"  # replace with the correct path if needed\n",
    "\n",
    "# Read and convert image from BGR to RGB (OpenCV loads in BGR)\n",
    "img = cv2.imread(img_path)\n",
    "if img is None:\n",
    "    print(\"Image not found. Check the path!\")\n",
    "else:\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Show image using matplotlib\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Detected License Plate\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2ebee-b565-4f75-a4cd-093df138cad1",
   "metadata": {},
   "source": [
    "CROPPING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3a98dd2-96ce-4c0c-9f7f-dab0dd9e85eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\RoadSafeAi\\data\\wild\\test\\images\\samplemanthan.jpg: 640x448 1 license_plate, 103.1ms\n",
      "Speed: 4.3ms preprocess, 103.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained detection model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")  # Adjust path if needed\n",
    "\n",
    "# Inference on an image\n",
    "image_path = r\"C:\\RoadSafeAi\\data\\wild\\test\\images\\samplemanthan.jpg\"\n",
    "results = model(image_path)\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Loop over detections and crop each license plate\n",
    "for i, box in enumerate(results[0].boxes.xyxy):\n",
    "    x1, y1, x2, y2 = map(int, box)  # Convert to int\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Save cropped image\n",
    "    cv2.imwrite(f\"Newcropped_plate_{i}.jpg\", cropped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa042b36-f303-4777-98df-417bc19c48e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1007_jpg.rf.4ac32a69f1e7076f0073c9c085118622.jpg: 640x640 2 license_plates, 143.1ms\n",
      "Speed: 5.3ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1007_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1007_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1009_jpg.rf.801b2d8b8ae47a0dbdf83941a657df4e.jpg: 640x640 2 license_plates, 137.1ms\n",
      "Speed: 5.7ms preprocess, 137.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1009_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1009_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1032_jpg.rf.e0d27860006cd1866022d954749d7802.jpg: 640x640 1 license_plate, 187.3ms\n",
      "Speed: 5.1ms preprocess, 187.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1032_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1085_jpg.rf.0856b80db523ef86750d23804c7f60b6.jpg: 640x640 3 license_plates, 146.7ms\n",
      "Speed: 3.8ms preprocess, 146.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1085_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1085_jpg_plate1.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1085_jpg_plate2.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1121_jpg.rf.528429388f6a612de341d814cf9ee1b9.jpg: 640x640 1 license_plate, 180.5ms\n",
      "Speed: 5.6ms preprocess, 180.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1121_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1125_jpg.rf.809a2fbb9d825acbbd586af066643ac7.jpg: 640x640 1 license_plate, 154.7ms\n",
      "Speed: 5.4ms preprocess, 154.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1125_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1194_jpg.rf.cbf7ffb89e65085f212c40b20a912cad.jpg: 640x640 1 license_plate, 141.7ms\n",
      "Speed: 6.6ms preprocess, 141.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1194_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1291_jpg.rf.1519d8fed677b2cd75f1b48b68cda2d7.jpg: 640x640 2 license_plates, 194.2ms\n",
      "Speed: 6.5ms preprocess, 194.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1291_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1291_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1312_jpg.rf.df28764a15b94cd2cf387e7971df7728.jpg: 640x640 1 license_plate, 154.5ms\n",
      "Speed: 6.2ms preprocess, 154.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1312_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1373_jpg.rf.2ba602d738fe9bd0d87b9b07d1c0eb8e.jpg: 640x640 1 license_plate, 135.5ms\n",
      "Speed: 5.2ms preprocess, 135.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1373_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1490_jpg.rf.199cefcd247f4322a796e477a3d626b3.jpg: 640x640 1 license_plate, 173.2ms\n",
      "Speed: 7.2ms preprocess, 173.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1490_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1535_jpg.rf.63b10413d40d3c65387df008061c1343.jpg: 640x640 2 license_plates, 152.7ms\n",
      "Speed: 8.9ms preprocess, 152.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1535_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1535_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1567_jpg.rf.9ed4a009ebca0afed8cb22e6e9cc931f.jpg: 640x640 1 license_plate, 146.9ms\n",
      "Speed: 8.9ms preprocess, 146.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1567_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1573_jpg.rf.fb12a2fd544264bfd8994f2d505ff528.jpg: 640x640 1 license_plate, 143.4ms\n",
      "Speed: 5.3ms preprocess, 143.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1573_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1603_jpg.rf.d790b6ffc565bb6f8fe917beb04ad086.jpg: 640x640 1 license_plate, 129.5ms\n",
      "Speed: 6.5ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1603_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1653_jpg.rf.c481b8619893bb67915808f89714c6ba.jpg: 640x640 1 license_plate, 146.2ms\n",
      "Speed: 5.5ms preprocess, 146.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1653_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1661_jpg.rf.62148cfdeacda2f4f4398c004b794bf7.jpg: 640x640 1 license_plate, 139.7ms\n",
      "Speed: 4.9ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1661_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1681_jpg.rf.99bbd25800cd393e0145792cd0da7eb7.jpg: 640x640 2 license_plates, 140.6ms\n",
      "Speed: 6.3ms preprocess, 140.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1681_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1681_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1813_jpg.rf.1305449a976f7c5457d92f56605aa946.jpg: 640x640 3 license_plates, 137.4ms\n",
      "Speed: 7.4ms preprocess, 137.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1813_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1813_jpg_plate1.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1813_jpg_plate2.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1863_jpg.rf.f973f509a55171c2d4ac5a423bf65ac0.jpg: 640x640 1 license_plate, 119.6ms\n",
      "Speed: 6.0ms preprocess, 119.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1863_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1903_jpg.rf.86f4933e07c21061bdabf3a965687e6d.jpg: 640x640 1 license_plate, 124.3ms\n",
      "Speed: 4.0ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1903_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1925_jpg.rf.cbcc962fda9b910bc4e0c23f1dbe7f60.jpg: 640x640 1 license_plate, 120.2ms\n",
      "Speed: 4.1ms preprocess, 120.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1925_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1939_jpg.rf.0bf90208e2770426fc9b7874c7b1f7e4.jpg: 640x640 1 license_plate, 130.2ms\n",
      "Speed: 3.9ms preprocess, 130.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1939_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_1959_jpg.rf.0a3a7b397cd205a56ad22bbc7b588e32.jpg: 640x640 2 license_plates, 177.6ms\n",
      "Speed: 8.0ms preprocess, 177.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1959_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_1959_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2002_jpg.rf.ddedfed336b4e11527b0331b980a94db.jpg: 640x640 1 license_plate, 167.7ms\n",
      "Speed: 7.9ms preprocess, 167.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2002_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2112_jpg.rf.3a7509a9df2ddb35963055adcc0f4622.jpg: 640x640 1 license_plate, 142.8ms\n",
      "Speed: 5.6ms preprocess, 142.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2112_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2122_jpg.rf.6c6e53a29a963fd7b7fc4ec548ef8043.jpg: 640x640 1 license_plate, 172.2ms\n",
      "Speed: 4.0ms preprocess, 172.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2122_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2131_jpg.rf.1a7f599f5d9ebe8f64d8037b7de2018d.jpg: 640x640 1 license_plate, 159.8ms\n",
      "Speed: 11.7ms preprocess, 159.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2131_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2156_jpg.rf.205aa3fa0ccbced18fdf8c71065f1e2b.jpg: 640x640 2 license_plates, 134.6ms\n",
      "Speed: 5.6ms preprocess, 134.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2156_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2156_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2158_jpg.rf.0a2c48a41a0d060e33d3bf76a78ba209.jpg: 640x640 1 license_plate, 158.3ms\n",
      "Speed: 5.3ms preprocess, 158.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2158_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2207_jpg.rf.6ed0968fb9d4da2410d71a4e1767cd4a.jpg: 640x640 1 license_plate, 124.7ms\n",
      "Speed: 4.2ms preprocess, 124.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2207_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2242_jpg.rf.c895b0927e75cdb1cfaea0fe7a151fb5.jpg: 640x640 1 license_plate, 211.6ms\n",
      "Speed: 4.7ms preprocess, 211.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2242_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2250_jpg.rf.e81d436beb18f696be0fd99bd9c071f3.jpg: 640x640 1 license_plate, 155.0ms\n",
      "Speed: 5.9ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2250_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2361_jpg.rf.2fc6da7cd417f9e9d0f95e7f7825a01a.jpg: 640x640 1 license_plate, 169.3ms\n",
      "Speed: 5.2ms preprocess, 169.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2361_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2396_jpg.rf.1d3065f4667d8c85a32231dd438c9a1a.jpg: 640x640 1 license_plate, 146.3ms\n",
      "Speed: 4.8ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2396_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2404_jpg.rf.e79e7c4afd6f4ff42d26b41f96951352.jpg: 640x640 1 license_plate, 122.1ms\n",
      "Speed: 4.2ms preprocess, 122.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2404_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2436_jpg.rf.bc77e0c4a63c38bdb2d5893ba706a0e1.jpg: 640x640 1 license_plate, 122.6ms\n",
      "Speed: 4.5ms preprocess, 122.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2436_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2479_jpg.rf.c9c9b6880cd792439819a4236035059b.jpg: 640x640 1 license_plate, 134.8ms\n",
      "Speed: 5.6ms preprocess, 134.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2479_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2531_jpg.rf.029e6d3d3efe7b1f1e2b97931c9befd1.jpg: 640x640 2 license_plates, 153.0ms\n",
      "Speed: 4.5ms preprocess, 153.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2531_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2531_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2555_jpg.rf.4d8835ebc91aae8f20368ebf8d013f60.jpg: 640x640 1 license_plate, 118.0ms\n",
      "Speed: 5.7ms preprocess, 118.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2555_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2569_jpg.rf.c7b6a00851cd368e6986c8093b3609f4.jpg: 640x640 2 license_plates, 116.1ms\n",
      "Speed: 5.6ms preprocess, 116.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2569_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2569_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2712_jpg.rf.9411a613ec76eaa30f1e5206d1df1f7c.jpg: 640x640 1 license_plate, 142.0ms\n",
      "Speed: 4.3ms preprocess, 142.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2712_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2732_jpg.rf.e3562baeca6e0952541b0614a2228287.jpg: 640x640 1 license_plate, 151.3ms\n",
      "Speed: 6.4ms preprocess, 151.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2732_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2749_jpg.rf.b9cd51ce3e11b5b948ebd7da281eaad4.jpg: 640x640 (no detections), 153.6ms\n",
      "Speed: 6.9ms preprocess, 153.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2768_jpg.rf.2ab76a252e25887b0234236e66ef4efd.jpg: 640x640 3 license_plates, 191.0ms\n",
      "Speed: 6.3ms preprocess, 191.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2768_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2768_jpg_plate1.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2768_jpg_plate2.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2812_jpg.rf.276096e2f6e4eb2de2d983d6e8aa4698.jpg: 640x640 1 license_plate, 132.2ms\n",
      "Speed: 4.1ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2812_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2816_jpg.rf.70834d5b7b47d50984ff651cd98eead2.jpg: 640x640 1 license_plate, 151.2ms\n",
      "Speed: 6.2ms preprocess, 151.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2816_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2872_jpg.rf.91b30e75912807b1d36f55947e2521ab.jpg: 640x640 1 license_plate, 145.9ms\n",
      "Speed: 4.9ms preprocess, 145.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2872_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2890_jpg.rf.8731cc7b8aaf0d745f652d9dcdf247bb.jpg: 640x640 1 license_plate, 139.7ms\n",
      "Speed: 6.5ms preprocess, 139.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2890_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2907_jpg.rf.3a6afb07a2181696ab28ab80b6a50a3d.jpg: 640x640 1 license_plate, 197.8ms\n",
      "Speed: 6.1ms preprocess, 197.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2907_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2916_jpg.rf.f82fa9476dcdaec25d62d90f301a3865.jpg: 640x640 1 license_plate, 171.2ms\n",
      "Speed: 7.8ms preprocess, 171.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2916_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_2947_jpg.rf.a8d9848446294f99a9c94b6a270a977a.jpg: 640x640 1 license_plate, 139.3ms\n",
      "Speed: 6.3ms preprocess, 139.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_2947_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3040_jpg.rf.852b2bc30183e29eaaab66ab893bffc4.jpg: 640x640 1 license_plate, 213.2ms\n",
      "Speed: 5.6ms preprocess, 213.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3040_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3043_jpg.rf.bbb2d85d0f2eeff6dc46581f11c674e5.jpg: 640x640 1 license_plate, 169.4ms\n",
      "Speed: 6.7ms preprocess, 169.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3043_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3050_jpg.rf.da6488c0d005b891c5df67d3953743d1.jpg: 640x640 2 license_plates, 183.9ms\n",
      "Speed: 6.3ms preprocess, 183.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3050_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3050_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3155_jpg.rf.b2133487dd75fda7e900968a28c76aaa.jpg: 640x640 1 license_plate, 202.7ms\n",
      "Speed: 5.7ms preprocess, 202.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3155_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3157_jpg.rf.70c5d37ad0442ad4da6818faf1a15dbf.jpg: 640x640 2 license_plates, 147.3ms\n",
      "Speed: 7.2ms preprocess, 147.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3157_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3157_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3186_jpg.rf.3e9a47e5e16e0fac879c82195a08c381.jpg: 640x640 1 license_plate, 178.5ms\n",
      "Speed: 12.2ms preprocess, 178.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3186_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3206_jpg.rf.951259f3c7cc7bf4e29099a598538f34.jpg: 640x640 1 license_plate, 149.0ms\n",
      "Speed: 11.2ms preprocess, 149.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3206_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3226_jpg.rf.4092ec244b7d08a41c71c11ddb39868d.jpg: 640x640 1 license_plate, 172.6ms\n",
      "Speed: 6.0ms preprocess, 172.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3226_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3230_jpg.rf.696c15bb9463f42e251ffa07cb0e5a79.jpg: 640x640 1 license_plate, 144.9ms\n",
      "Speed: 7.3ms preprocess, 144.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3230_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3245_jpg.rf.a2fa888d97cd785f631847c67009037f.jpg: 640x640 1 license_plate, 117.8ms\n",
      "Speed: 4.7ms preprocess, 117.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3245_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3280_jpg.rf.e06fd382256c65db3915a5bbea73ce9a.jpg: 640x640 3 license_plates, 121.2ms\n",
      "Speed: 4.5ms preprocess, 121.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3280_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3280_jpg_plate1.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3280_jpg_plate2.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3282_jpg.rf.a64acd306ddc28755ab20623fc21bc09.jpg: 640x640 1 license_plate, 173.4ms\n",
      "Speed: 7.3ms preprocess, 173.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3282_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3323_jpg.rf.d74fd0c963a86371d76c69a5bef6c065.jpg: 640x640 1 license_plate, 180.6ms\n",
      "Speed: 5.3ms preprocess, 180.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3323_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3352_jpg.rf.8fee2647616f96ea214bea2df3ea3546.jpg: 640x640 1 license_plate, 138.5ms\n",
      "Speed: 5.7ms preprocess, 138.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3352_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3394_jpg.rf.36f6ab977fc8cab586b061df8821b318.jpg: 640x640 1 license_plate, 161.0ms\n",
      "Speed: 4.7ms preprocess, 161.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3394_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3410_jpg.rf.4b016043ae8f3dbe641a09453af01f84.jpg: 640x640 2 license_plates, 160.0ms\n",
      "Speed: 5.3ms preprocess, 160.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3410_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3410_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3412_jpg.rf.e806a414322ff24ff0e4007869eb19b5.jpg: 640x640 1 license_plate, 102.9ms\n",
      "Speed: 4.1ms preprocess, 102.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3412_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3433_jpg.rf.96344727301610250ac608c76c85dd60.jpg: 640x640 1 license_plate, 177.2ms\n",
      "Speed: 3.6ms preprocess, 177.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3433_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3483_jpg.rf.fce91f6a13e171a646015d8a79fa9b96.jpg: 640x640 1 license_plate, 116.3ms\n",
      "Speed: 5.0ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3483_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3525_jpg.rf.7de8649f53df9f74d5f8c69badb66899.jpg: 640x640 1 license_plate, 110.5ms\n",
      "Speed: 4.2ms preprocess, 110.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3525_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3591_jpg.rf.e8960f6f4670f6fcf9ed57ef8d8adc5b.jpg: 640x640 2 license_plates, 102.7ms\n",
      "Speed: 3.7ms preprocess, 102.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3591_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3591_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3860_jpg.rf.73e5404917390163febdbdb0560f178a.jpg: 640x640 1 license_plate, 130.9ms\n",
      "Speed: 4.0ms preprocess, 130.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3860_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3867_jpg.rf.6bb7972f074144a62c81a0861c2f2d4a.jpg: 640x640 2 license_plates, 120.6ms\n",
      "Speed: 4.4ms preprocess, 120.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3867_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3867_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3875_jpg.rf.b44e6f67fd55e2ae666a0cde23b6951d.jpg: 640x640 2 license_plates, 129.9ms\n",
      "Speed: 4.5ms preprocess, 129.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3875_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3875_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_3899_jpg.rf.59da19d090f58d36a4bf76ee33dc0c28.jpg: 640x640 1 license_plate, 117.9ms\n",
      "Speed: 4.8ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_3899_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_642_jpg.rf.b8dfed98d0d2dc73204bb9f4cb526e43.jpg: 640x640 2 license_plates, 115.6ms\n",
      "Speed: 4.1ms preprocess, 115.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_642_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_642_jpg_plate1.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_700_jpg.rf.cefe4f705c5bbc03ffd23f834df445a6.jpg: 640x640 1 license_plate, 117.0ms\n",
      "Speed: 4.3ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_700_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_737_jpg.rf.45c41b8a4542e3e550763478d12706f8.jpg: 640x640 1 license_plate, 113.2ms\n",
      "Speed: 4.3ms preprocess, 113.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_737_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_750_jpg.rf.cee97822b4aa77b9986fc5e44ec521fc.jpg: 640x640 3 license_plates, 130.4ms\n",
      "Speed: 5.1ms preprocess, 130.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_750_jpg_plate0.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_750_jpg_plate1.jpg\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_750_jpg_plate2.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_843_jpg.rf.162af36854c190ce7bae14667cb569ed.jpg: 640x640 1 license_plate, 135.8ms\n",
      "Speed: 5.2ms preprocess, 135.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_843_jpg_plate0.jpg\n",
      "\n",
      "image 1/1 C:\\Users\\Vidya\\Desktop\\wild\\test\\images\\drop-car-front_844_jpg.rf.7e5447aceff70dfd225e9f12e1dbd1f9.jpg: 640x640 1 license_plate, 122.0ms\n",
      "Speed: 4.7ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plate saved to: C:/Users/Vidya/Desktop/wild/cropped_plates\\drop-car-front_844_jpg_plate0.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")  # Adjust if your path is different\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = \"C:/RoadSafeAi/data/wild/test/images\"  # or train/val\n",
    "output_folder = \"C:/RoadSafeAi/data/wild/cropped_plates\"\n",
    "\n",
    "# Make sure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through all images and save cropped plates\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        results = model(image_path)\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "            for j, box in enumerate(result.boxes):\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "                output_path = os.path.join(output_folder, f\"{filename.split('.')[0]}_plate{j}.jpg\")\n",
    "                cv2.imwrite(output_path, cropped)\n",
    "                print(f\"Cropped plate saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9dd0c9-64ad-4f4e-a92b-729935b7c133",
   "metadata": {},
   "source": [
    "trying to print image here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "514b982d-3e8c-4fdd-bb41-feb651cc3f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(\"WhatsApp Image 2025-04-09 at 21.19.40_918df46e.jpg\")\n",
    "\n",
    "# Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image in the notebook\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Optional: turn off axis\n",
    "plt.title(\"License Plate Detection Result\")  \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82efd6d-8ae3-42c2-8b0b-9ef50d14d25e",
   "metadata": {},
   "source": [
    "ACCURACY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf20233d-6bc7-410d-ae92-becbd82b0a1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.104  Python-3.11.8 torch-2.6.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "'C:\\wild\\data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33mruns/detect/train/weights/best.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Update path if needed\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Evaluate the model on the validation dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m metrics = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Print key evaluation metrics\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Evaluation Metrics ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:628\u001b[39m, in \u001b[36mModel.val\u001b[39m\u001b[34m(self, validator, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m args = {**\u001b[38;5;28mself\u001b[39m.overrides, **custom, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[32m    627\u001b[39m validator = (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._smart_load(\u001b[33m\"\u001b[39m\u001b[33mvalidator\u001b[39m\u001b[33m\"\u001b[39m))(args=args, _callbacks=\u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = validator.metrics\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m validator.metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\validator.py:179\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    176\u001b[39m     LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSetting batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.args.batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m input of shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.args.batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, 3, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.args.data).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33myaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myml\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.task == \u001b[33m\"\u001b[39m\u001b[33mclassify\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = check_cls_dataset(\u001b[38;5;28mself\u001b[39m.args.data, split=\u001b[38;5;28mself\u001b[39m.args.split)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\data\\utils.py:312\u001b[39m, in \u001b[36mcheck_det_dataset\u001b[39m\u001b[34m(dataset, autodownload)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_det_dataset\u001b[39m(dataset, autodownload=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    298\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[33;03m    Download, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m        (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m     \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n\u001b[32m    315\u001b[39m     extract_dir = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\utils\\checks.py:546\u001b[39m, in \u001b[36mcheck_file\u001b[39m\u001b[34m(file, suffix, download, download_dir, hard)\u001b[39m\n\u001b[32m    544\u001b[39m files = glob.glob(\u001b[38;5;28mstr\u001b[39m(ROOT / \u001b[33m\"\u001b[39m\u001b[33m**\u001b[39m\u001b[33m\"\u001b[39m / file), recursive=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m glob.glob(\u001b[38;5;28mstr\u001b[39m(ROOT.parent / file))  \u001b[38;5;66;03m# find file\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[32m    548\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMultiple files match \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, specify exact path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: 'C:\\wild\\data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")  # Update path if needed\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "metrics = model.val()\n",
    "\n",
    "# Print key evaluation metrics\n",
    "print(\"\\n--- Evaluation Metrics ---\")\n",
    "print(f\"Precision     : {metrics.box.precision:.4f}\")\n",
    "print(f\"Recall        : {metrics.box.recall:.4f}\")\n",
    "print(f\"mAP@0.5       : {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95  : {metrics.box.map:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9daff-04ff-4a65-99e0-d6e8c304b230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Ultralytics)",
   "language": "python",
   "name": "ultra311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
